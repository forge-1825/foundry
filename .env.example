# Model Distillation Pipeline Environment Variables
# Copy this file to .env and update with your configuration

# ===== Application Settings =====
# The directory where data files will be stored
DATA_DIR=/path/to/your/data/directory

# ===== API Configuration =====
# API key for vLLM server (optional, defaults to 'not-needed')
VLLM_API_KEY=not-needed

# Base URL for vLLM server
VLLM_BASE_URL=http://localhost:8000/v1

# Use remote models via SSH port forwarding (true/false)
USE_REMOTE_MODELS=true

# ===== Server Configuration =====
# Backend server settings
BACKEND_HOST=0.0.0.0
BACKEND_PORT=7433

# Frontend server settings
FRONTEND_HOST=0.0.0.0
FRONTEND_PORT=3456

# ===== Docker Configuration =====
# Host IP for Docker networking (usually auto-detected)
# Uncomment and set if you have issues with Docker networking
# HOST_IP=192.168.1.100

# ===== Model Endpoints =====
# Teacher model endpoint
TEACHER_MODEL_URL=http://localhost:8000/v1
TEACHER_MODEL_NAME=jakiAJK/microsoft-phi-4_GPTQ-int4

# Student model endpoint
STUDENT_MODEL_URL=http://localhost:8002/v1
STUDENT_MODEL_NAME=microsoft/phi-3-mini-4k-instruct

# ===== Logging Configuration =====
# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log file location (optional)
# LOG_FILE=/path/to/logfile.log

# ===== Resource Limits =====
# Maximum file size for uploads (in MB)
MAX_FILE_SIZE=100

# Maximum number of concurrent processes
MAX_CONCURRENT_PROCESSES=4

# ===== Feature Flags =====
# Enable debug mode (true/false)
DEBUG=false

# Enable GPU support (true/false)
ENABLE_GPU=true